{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6972452-c2f3-4612-93d7-6809861a797c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /mnt/data/2023-kaggle-final/store-sales/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72cd6878-7eed-4889-8d48-cc49a42a8f10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca305302-0f0b-49b6-b7e2-a26542d316b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8996c93-24a4-4047-a39d-a04109e93a17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "userName = spark.sql(\"SELECT CURRENT_USER\").collect()[0]['current_user()']\n",
    "userName0 = userName.split(\"@\")[0]\n",
    "userName0 = re.sub('[!#$%&\\'*+-/=?^`{}|\\.]+', '_', userName0)\n",
    "userName1 = userName.split(\"@\")[1]\n",
    "userName = f'{userName0}@{userName1}'\n",
    "dbutils.fs.mkdirs(f\"/Users/{userName}/data\")\n",
    "userDir = f\"/Users/{userName}/data\"\n",
    "databaseName = f\"{userName0}_FinalProject_01\"\n",
    "\n",
    "print('databaseName ' + databaseName)\n",
    "print('UserDir ' + userDir)\n",
    "\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {databaseName}\")\n",
    "spark.sql(f\"use {databaseName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d02510-1270-4c99-8cdb-7478b2fd3504",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a AutoLoader to load the files from the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00fe432-bd82-483d-a32c-f4fa7b670ca8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('UserDir ' + userDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "739bcf58-b173-4ff3-8408-a9aaf03e6360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rawDataSource='dbfs:/mnt/data/2023-kaggle-final/store-sales'\n",
    "#rawDataSource='/mnt/data/2023-kaggle-final/store-sales'\n",
    "bronzeCheckpoint = f\"{userDir}/bronze_check_point\"\n",
    "bronzeTable = f\"{userDir}/bronze\"\n",
    "bronzeSchema = f\"{userDir}/bronze_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d40b0f7-fe69-401b-a191-7f51b4e24bba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Users/veg940@g.harvard.edu/data/bronze_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42455089-caad-4b48-9f69-247868163866",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Users/veg940@g.harvard.edu/data/bronze_check_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cb0bff9-358c-46dc-b314-9a2904ecbe1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Working streaming example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1749399a-3eec-464d-af81-6693714ad04a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import input_file_name,expr\n",
    "from pyspark.sql.types import ArrayType,IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09559f1e-9812-41c4-b626-f9fc68290b80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze Oil Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6229420-2151-4290-b809-cd430e2962b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", \"true\").load(f\"{rawDataSource}/oil.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e261896-db1d-49f4-bc6d-77394974869b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc91d5d2-f5d4-4ba3-b07e-a2146b8a71e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*oil*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "390afb1a-eae7-4682-922f-112af7872456",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls '/Users/veg940@g.harvard.edu/data/bronze_check_point/oil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59d7f07-4fd7-46d2-83bc-f5b3628cdbaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "oil_checkpoint_location = f\"{bronzeCheckpoint}/oil\"\n",
    "dbutils.fs.rm(oil_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "df.writeStream.option(\"checkpointLocation\", oil_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_oil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee61b9bb-9c05-4d3b-b3de-daec42b1f264",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40cc9300-e674-45e3-ad5b-9f1644fa1d7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze Stores Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa5fc210-04bc-4309-be68-7158d9ffdb67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_stores = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/stores.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6de452-d2ad-4b2e-b524-6f1ec0196a68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c785dea1-bae5-4138-8fc0-966baba3b510",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "storesDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*stores*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_stores) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2b991f-d1c0-4309-9fed-635d5467704f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(storesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bbcfaa6-9424-4b41-86bf-5106e275e9b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stores_checkpoint_location = f\"{bronzeCheckpoint}/bronzestores\"\n",
    "dbutils.fs.rm(stores_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "storesDF.writeStream.option(\"checkpointLocation\", stores_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_stores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dfc725e-63a5-4c98-8ab3-e8851c48cbb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_stores;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1d0cd6-8fb4-4504-80f1-8c46d54f54a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Bronze Data load for holidays_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4ca163-48b5-4069-991d-bd384cec8791",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_holidays_events = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/holidays_events.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c5e18b-4946-4413-86ab-ad25e625d08a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "holidaysEventsDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*holidays_events*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_holidays_events) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a328aedd-f6b4-419a-97c2-b92bf13cdb2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "holidayevents_checkpoint_location = f\"{bronzeCheckpoint}/holidayevents\"\n",
    "dbutils.fs.rm(holidayevents_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "holidaysEventsDF.writeStream.option(\"checkpointLocation\", holidayevents_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_holiday_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2763ff-8105-4d98-949f-1534dba80a8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_holiday_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71c5b6ee-3fa6-437c-b8aa-7036e95360af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Bronze Data load for transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93b7552-d04d-4a6a-ab16-6765f98fe9bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_transactions = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/transactions.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07c2c74d-d5d3-499b-a30b-fae5be217b14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6425643b-a17a-4e74-8543-aebd3ad0ab96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "transactionsDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*transactions*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_transactions) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b693b44c-43e7-498b-ae75-282cb5f90d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_checkpoint_location = f\"{bronzeCheckpoint}/transactions\"\n",
    "dbutils.fs.rm(transactions_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "transactionsDF.writeStream.option(\"checkpointLocation\", transactions_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb13049-83df-46e7-8734-d9dc9ff1d22a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "829f4e6a-c4c3-4ad9-9726-877c35e8e059",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Bronze Data load for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1458318f-7c79-48af-862c-78d0468df2f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_train = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/train.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "159b2b93-3693-430e-a2fb-e7d45d785d87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "trainDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*train*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_train) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0f10024-b1f7-41d0-9ac1-cce551065650",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93eb99da-c96f-44e6-a4a3-cc328bbe6b25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_checkpoint_location = f\"{bronzeCheckpoint}/train\"\n",
    "dbutils.fs.rm(train_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "trainDF.writeStream.option(\"checkpointLocation\", train_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "795eeab2-ff00-4cee-909e-92ccbda89f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Bronze Data load for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2426de8-fab0-4575-8658-9d11f48f412c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_test = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/test.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7174f244-73c1-4bcd-bed1-21c758878583",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "testDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*test*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_test) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c49519d5-16fb-40bd-96ea-3a1227f581ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_checkpoint_location = f\"{bronzeCheckpoint}/test\"\n",
    "dbutils.fs.rm(test_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "testDF.writeStream.option(\"checkpointLocation\", test_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d39c017-a8c8-44a8-974a-a37df41b3ce2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aaf4979-034e-4cf9-97dc-e4f884cd674a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dceeee54-ed6f-4ad8-858c-cc39f4127ce1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Bronze Data load for sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434531d9-e2b2-443c-a8bc-a502b3bf0a4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_sample_submission = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(f\"{rawDataSource}/sample_submission.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2925f399-0c9e-447c-8fc0-fbd92a7f1de6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files as a streaming DataFrame\n",
    "sampleSubmissionDF = df = spark.readStream.format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"csv\") \\\n",
    "  .option(\"pathGlobFilter\", \"*sample_submission*.csv\") \\\n",
    "  .option(\"header\", True) \\\n",
    "  .schema(schema_sample_submission) \\\n",
    "  .load(f\"{rawDataSource}\") \\\n",
    "  #.withColumn(\"filename\",input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff90cd8e-7708-4ea2-92b7-4d57dbf521c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "samplesubmission_checkpoint_location = f\"{bronzeCheckpoint}/samplesubmission\"\n",
    "dbutils.fs.rm(samplesubmission_checkpoint_location, True) #reset checkpoint so it reloads the file\n",
    "sampleSubmissionDF.writeStream.option(\"checkpointLocation\", samplesubmission_checkpoint_location).option(\"mergeSchema\", \"true\").table(\"bronze_samplesubmission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52a2c435-c42d-4403-92ee-b7bb26a9e1f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM bronze_samplesubmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be7608e4-560d-4c05-8b54-991e13c0a355",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231cadb2-7452-4e82-8459-a04ef37af4b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import input_file_name\n",
    "from pyspark.sql.types import ArrayType,IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e09a369-2272-4d84-902e-2faaea524a7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the tables using spark.read as batch for doing null checks, eda and transforming and deduplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a086d741-b0a4-4e95-bc37-a9b016618c1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "StorefilePath = [('dbfs:/mnt/data/2023-kaggle-final/store-sales/holidays_events.csv', 'holidays_events'),\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/oil.csv', 'oil'),\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/sample_submission.csv','sample_submission') ,\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/stores.csv','stores'),\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/test.csv','test_set'),\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/train.csv','train_set'),\n",
    "('dbfs:/mnt/data/2023-kaggle-final/store-sales/transactions.csv','transactions')]\n",
    "\n",
    "for file_name, tab_name in StorefilePath:\n",
    "  StoresDF = (spark.read\n",
    "    .option(\"sep\", \",\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(file_name))\n",
    "  StoresDF.createOrReplaceTempView(tab_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cb0e874-7bd8-4f73-8bff-92cefed86d83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Null checks and Handling Nulls by removing null rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916b1192-6a4f-448e-9bcf-244b9619dd72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "holiday_events_df = spark.sql(\"SELECT * FROM holidays_events\")\n",
    "display(holiday_events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc35dc18-6a60-4c82-b6e0-d6a5bba6d9dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Number of Rows after null were dropped, the entire row will be dropped even if any of the column value is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0d0707b-a320-4041-8da2-eb9187151d40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "holiday_dropna_events_df = holiday_events_df.dropna(\"any\")\n",
    "display(holiday_dropna_events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c601b28a-4891-458b-92e9-45ddd19bdce7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "oil_df=spark.sql(\"SELECT * FROM oil\")\n",
    "display(oil_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df2fc50-659b-4476-a2b1-ef782f9b27dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "oil_dropna_df = oil_df.dropna(\"any\")\n",
    "display(oil_dropna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caee2154-da1c-4873-8617-eaae9b9f9199",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_submission_df = spark.sql(\"SELECT * FROM sample_submission\")\n",
    "display(sample_submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f871e85c-a753-4a97-b96d-1f53922ad666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_submission_dropna_df = sample_submission_df.dropna(\"any\")\n",
    "display(sample_submission_dropna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b14de1ad-5815-4987-8715-a8c2d16082d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stores_df = spark.sql(\"SELECT * FROM stores\")\n",
    "display(stores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d626b2-c4c2-493d-a849-d4fd7a14eca7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stores_dropna_df = stores_df.dropna(\"any\")\n",
    "display(stores_dropna_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b68ec4c-28a3-4342-badd-6a97ee73cab9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df = spark.sql(\"SELECT * FROM test_set\")\n",
    "#display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8179dc74-142a-4cad-8391-4775e8888096",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_dropna_df = test_df.dropna(\"any\")\n",
    "#display(test_dropna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae26ee1b-9ef7-4994-b6fe-7e3c219d844b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = spark.sql(\"SELECT * FROM train_set\")\n",
    "#display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc726178-f186-4a64-bee4-1a0f827b9f64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_dropna_df = train_df.dropna(\"any\")\n",
    "#display(train_dropna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35c5f1b-f770-44e5-925e-c1f514659ab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_df = spark.sql(\"SELECT * FROM transactions\")\n",
    "display(transactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf339fe-ef91-4c84-8b8e-9193f0645469",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_dropna_df = transactions_df.dropna(\"any\")\n",
    "display(transactions_dropna_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd6d8d79-a95a-4430-8ba6-e93d9c5a1561",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6edab32-4675-44cd-ad50-72bf1c9c5102",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pandas_df = train_dropna_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abefe9cd-c016-41b1-9223-fd158898ac1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Check any correlation exists in train_set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b005b40-e596-4e13-aeaf-1a5ef926df89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Correlation Scatter Plot between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93500f71-ab06-4096-b80e-71a483302877",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(pandas_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cbd68af-3125-46c3-8070-8db16c24c168",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We could observe there is a relationship exists between on promotion predictor and sales (target variable) and observed one or two outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ebd8640-7b22-4e67-82ba-e0b51c85e3eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**2. Check any impact on oil price with target variable(sales)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d643b69-a4db-4ec3-a6d5-4cb77325ceac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(oil_dropna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b19ac34-0be8-4c86-b625-7fa30e426c5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merging Oil Price DF with Train DataSEt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40dd6742-3f6c-4083-812d-983d517f6fbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11089572-a80d-44b1-aff4-1c9ed4d0eb65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert string date column to date type\n",
    "df1 = oil_df.withColumn(\"date\", col(\"date\").cast(\"date\"))\n",
    "df2 = train_df.withColumn(\"date\", col(\"date\").cast(\"date\"))\n",
    "\n",
    "# Joining DataFrames on the 'date' column\n",
    "joined_df = df1.join(df2, on='date', how='inner')\n",
    "\n",
    "# Display the joined DataFrame\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2c33c68-5485-41ad-a397-ebe45f580b0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scatter Plot between Sales and Oil Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06444eee-21e6-4448-87f6-84c11ffc292c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Collect the data for the two columns\n",
    "data_to_plot = joined_df.select('sales', 'dcoilwtico').collect()\n",
    "\n",
    "# Extract values for plotting\n",
    "x = [row['dcoilwtico'] for row in data_to_plot]\n",
    "y = [row['sales'] for row in data_to_plot]\n",
    "\n",
    "# Plotting a scatter plot using Matplotlib\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Oil Price')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Scatter Plot between Oil Price and Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ac076e8-572f-44da-9bb8-ac29f06a5467",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Analysis: As the oil price increases, the sales havent increased.<br>\n",
    "Observed 1 outlier,  that might skew the data and might impact modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37627baa-456f-457e-bf5c-e43881b48948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "951a34d6-fc93-4ee8-a0aa-be78af3b9082",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df.createTempView(\"train_with_oilprice\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1179881668952770,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Bronze_Venkatesh",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
