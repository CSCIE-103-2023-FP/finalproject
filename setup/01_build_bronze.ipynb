{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8996c93-24a4-4047-a39d-a04109e93a17",
     "showTitle": true,
     "title": "Rebuild the database"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "userName = spark.sql(\"SELECT CURRENT_USER\").collect()[0]['current_user()']\n",
    "userName0 = userName.split(\"@\")[0]\n",
    "userName0 = re.sub('[!#$%&\\'*+-/=?^`{}|\\.]+', '_', userName0)\n",
    "userName1 = userName.split(\"@\")[1]\n",
    "userName = f'{userName0}@{userName1}'\n",
    "dbutils.fs.mkdirs(f\"/Users/{userName}/data\")\n",
    "userDir = f\"/Users/{userName}/data\"\n",
    "databaseName = f\"{userName0}_FinalProject_01\"\n",
    "\n",
    "print('databaseName ' + databaseName)\n",
    "print('UserDir ' + userDir)\n",
    "\n",
    "spark.sql(f\"DROP DATABASE IF EXISTS {databaseName} CASCADE\")\n",
    "spark.sql(f\"CREATE DATABASE {databaseName}\")\n",
    "spark.sql(f\"use {databaseName}\")\n",
    "\n",
    "print (f\"Database {databaseName} successfully rebuilt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9cc1710-9d84-4d17-9932-fbdc0821a62a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /mnt/data/2023-kaggle-final/store-sales/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9aa7271-5539-4e39-88de-68eee3680b28",
     "showTitle": true,
     "title": "Load Bronze Tables"
    }
   },
   "outputs": [],
   "source": [
    "rootPath = \"dbfs:/mnt/data/2023-kaggle-final/store-sales/\"\n",
    "\n",
    "for file in dbutils.fs.ls(rootPath):\n",
    "  tableName = \"bronze_\" + file.name.replace('.csv', '')\n",
    "  print (f\"processing file {file.name} into table name {tableName}...\")\n",
    "\n",
    "  loadDf = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file.path)\n",
    "  loadDf.write.saveAsTable(tableName) #saves delta table\n",
    "  \n",
    "  print(f\"Successfully saved delta table {tableName}.\")\n",
    "  print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 241878872965362,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01_build_bronze",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
